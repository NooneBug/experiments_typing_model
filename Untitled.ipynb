{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tries with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\")\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased', padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer([\"I am Manuel\", \"hi\", \"this is a very long sentence\"], \n",
    "          padding='max_length',\n",
    "          max_length = 25,\n",
    "          truncation=True, \n",
    "          return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 101, 1045, 2572, 7762,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0]),\n",
       " tensor([ 101, 7632,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0]),\n",
       " tensor([ 101, 2023, 2003, 1037, 2200, 2146, 6251,  102,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.tensor(t) for t in tokens['input_ids'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, _ = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 25, 1024])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 25, 1024])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([output, output]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVGPool try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3]],\n",
       "\n",
       "        [[4, 5, 6]],\n",
       "\n",
       "        [[7, 8, 9]]], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3]],\n",
       "\n",
       "        [[4, 5, 6]],\n",
       "\n",
       "        [[7, 8, 9]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = torch.ones((100, 25, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = torch.nn.AvgPool2d((25,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = pool(ones).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token number try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=1024, nhead=8)\n",
    "mention_transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/datahdd/vmanuel/entity_typing_all_datasets/data/ontonotes/g_train_tree.json', 'r') as inp:\n",
    "    lines = [json.loads(l) for l in inp.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [00:43<00:00, 5826.02it/s]\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for l in tqdm(lines):\n",
    "    mention = l['mention_span']\n",
    "    t = tokenizer(mention)\n",
    "    lengths.append(len(t['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3745234804153936"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 190148,\n",
       "         4: 39663,\n",
       "         5: 13143,\n",
       "         6: 5653,\n",
       "         7: 1575,\n",
       "         10: 63,\n",
       "         8: 596,\n",
       "         11: 30,\n",
       "         9: 135,\n",
       "         13: 9,\n",
       "         12: 15,\n",
       "         16: 5,\n",
       "         15: 2,\n",
       "         19: 1,\n",
       "         14: 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [01:31<00:00, 2742.66it/s]\n"
     ]
    }
   ],
   "source": [
    "l_lengths = []\n",
    "for l in tqdm(lines):\n",
    "    mention = ' '.join(l['left_context_token'])\n",
    "    t = tokenizer(mention)\n",
    "    l_lengths.append(len(t['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.155844311043303"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(l_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({21: 4088,\n",
       "         3: 10414,\n",
       "         2: 53417,\n",
       "         10: 7952,\n",
       "         5: 8564,\n",
       "         9: 8311,\n",
       "         23: 3620,\n",
       "         7: 8999,\n",
       "         8: 9031,\n",
       "         13: 7115,\n",
       "         4: 10033,\n",
       "         6: 8990,\n",
       "         56: 375,\n",
       "         11: 7706,\n",
       "         12: 7330,\n",
       "         14: 6776,\n",
       "         18: 5183,\n",
       "         20: 4614,\n",
       "         25: 3195,\n",
       "         16: 5763,\n",
       "         24: 3354,\n",
       "         17: 5403,\n",
       "         27: 2942,\n",
       "         19: 4821,\n",
       "         28: 2643,\n",
       "         32: 1933,\n",
       "         15: 6354,\n",
       "         46: 710,\n",
       "         33: 1912,\n",
       "         43: 890,\n",
       "         55: 448,\n",
       "         22: 4011,\n",
       "         29: 2547,\n",
       "         45: 792,\n",
       "         42: 1049,\n",
       "         54: 450,\n",
       "         30: 2345,\n",
       "         49: 630,\n",
       "         34: 1720,\n",
       "         26: 3145,\n",
       "         40: 1131,\n",
       "         36: 1485,\n",
       "         53: 417,\n",
       "         38: 1317,\n",
       "         37: 1482,\n",
       "         31: 2151,\n",
       "         35: 1724,\n",
       "         39: 1195,\n",
       "         41: 1053,\n",
       "         66: 187,\n",
       "         48: 647,\n",
       "         51: 456,\n",
       "         47: 682,\n",
       "         60: 311,\n",
       "         67: 207,\n",
       "         44: 891,\n",
       "         58: 366,\n",
       "         52: 408,\n",
       "         50: 522,\n",
       "         64: 186,\n",
       "         105: 9,\n",
       "         100: 21,\n",
       "         84: 34,\n",
       "         86: 54,\n",
       "         82: 65,\n",
       "         62: 205,\n",
       "         69: 131,\n",
       "         57: 300,\n",
       "         61: 295,\n",
       "         59: 222,\n",
       "         72: 120,\n",
       "         63: 176,\n",
       "         65: 152,\n",
       "         73: 142,\n",
       "         74: 125,\n",
       "         71: 108,\n",
       "         79: 106,\n",
       "         87: 62,\n",
       "         75: 118,\n",
       "         78: 94,\n",
       "         81: 59,\n",
       "         77: 101,\n",
       "         68: 161,\n",
       "         70: 163,\n",
       "         76: 64,\n",
       "         85: 20,\n",
       "         110: 16,\n",
       "         106: 28,\n",
       "         111: 14,\n",
       "         118: 32,\n",
       "         91: 40,\n",
       "         83: 63,\n",
       "         144: 5,\n",
       "         121: 15,\n",
       "         103: 13,\n",
       "         112: 5,\n",
       "         107: 24,\n",
       "         104: 34,\n",
       "         80: 63,\n",
       "         120: 2,\n",
       "         88: 42,\n",
       "         90: 32,\n",
       "         102: 23,\n",
       "         130: 7,\n",
       "         128: 12,\n",
       "         129: 16,\n",
       "         172: 25,\n",
       "         165: 17,\n",
       "         89: 69,\n",
       "         153: 33,\n",
       "         123: 18,\n",
       "         94: 57,\n",
       "         117: 9,\n",
       "         193: 1,\n",
       "         95: 53,\n",
       "         92: 62,\n",
       "         108: 27,\n",
       "         98: 17,\n",
       "         116: 15,\n",
       "         190: 15,\n",
       "         167: 9,\n",
       "         166: 7,\n",
       "         179: 14,\n",
       "         154: 2,\n",
       "         97: 23,\n",
       "         99: 45,\n",
       "         96: 36,\n",
       "         124: 25,\n",
       "         133: 3,\n",
       "         138: 13,\n",
       "         119: 22,\n",
       "         126: 3,\n",
       "         141: 20,\n",
       "         93: 38,\n",
       "         175: 1,\n",
       "         109: 9,\n",
       "         156: 7,\n",
       "         162: 4,\n",
       "         113: 11,\n",
       "         159: 4,\n",
       "         147: 7,\n",
       "         131: 6,\n",
       "         142: 17,\n",
       "         152: 24,\n",
       "         224: 1,\n",
       "         125: 2,\n",
       "         178: 1,\n",
       "         146: 2,\n",
       "         198: 1,\n",
       "         219: 1,\n",
       "         206: 1,\n",
       "         232: 2,\n",
       "         245: 2,\n",
       "         258: 1,\n",
       "         211: 1,\n",
       "         157: 7,\n",
       "         237: 1,\n",
       "         170: 1,\n",
       "         158: 2,\n",
       "         122: 24,\n",
       "         150: 21,\n",
       "         135: 18,\n",
       "         140: 16,\n",
       "         145: 16,\n",
       "         143: 1,\n",
       "         136: 1,\n",
       "         101: 16,\n",
       "         336: 1,\n",
       "         250: 1,\n",
       "         171: 3,\n",
       "         212: 1,\n",
       "         207: 1,\n",
       "         210: 1,\n",
       "         127: 3,\n",
       "         296: 1,\n",
       "         313: 1,\n",
       "         267: 1,\n",
       "         229: 1,\n",
       "         334: 1,\n",
       "         248: 1,\n",
       "         338: 1,\n",
       "         231: 1,\n",
       "         191: 13,\n",
       "         134: 17,\n",
       "         148: 5,\n",
       "         132: 3,\n",
       "         161: 1,\n",
       "         204: 3,\n",
       "         155: 8,\n",
       "         184: 1,\n",
       "         192: 1,\n",
       "         196: 1,\n",
       "         194: 14,\n",
       "         169: 16,\n",
       "         183: 15,\n",
       "         188: 3,\n",
       "         149: 10,\n",
       "         168: 9,\n",
       "         287: 4,\n",
       "         139: 3})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2841"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESH = 70\n",
    "\n",
    "counter = 0\n",
    "for k, v in Counter(l_lengths).items():\n",
    "    if not k <= THRESH:\n",
    "        counter += v\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [01:55<00:00, 2164.71it/s]\n"
     ]
    }
   ],
   "source": [
    "r_lengths = []\n",
    "for l in tqdm(lines):\n",
    "    mention = ' '.join(l['right_context_token'])\n",
    "    t = tokenizer(mention)\n",
    "    r_lengths.append(len(t['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.28137859057756"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(r_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3707"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESH = 70\n",
    "\n",
    "counter = 0\n",
    "for k, v in Counter(r_lengths).items():\n",
    "    if not k <= THRESH:\n",
    "        counter += v\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 79038/251039 [00:59<03:16, 877.45it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      " 46%|████▌     | 114229/251039 [01:29<01:44, 1307.25it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      " 97%|█████████▋| 242962/251039 [03:01<00:11, 716.10it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 251039/251039 [03:07<00:00, 1338.03it/s]\n"
     ]
    }
   ],
   "source": [
    "c_lengths = []\n",
    "for l in tqdm(lines):\n",
    "    mention = ' '.join(l['right_context_token']) + ' '.join(l['right_context_token'])\n",
    "    t = tokenizer(mention)\n",
    "    c_lengths.append(len(t['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.57115428280068"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(c_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 20541,\n",
       "         40: 5924,\n",
       "         22: 8464,\n",
       "         32: 7079,\n",
       "         16: 8545,\n",
       "         26: 7776,\n",
       "         18: 8577,\n",
       "         14: 8601,\n",
       "         8: 7290,\n",
       "         20: 8377,\n",
       "         12: 8162,\n",
       "         10: 8769,\n",
       "         86: 1295,\n",
       "         24: 7925,\n",
       "         38: 6177,\n",
       "         44: 5266,\n",
       "         46: 4994,\n",
       "         72: 2148,\n",
       "         54: 3959,\n",
       "         28: 7611,\n",
       "         48: 4806,\n",
       "         42: 5521,\n",
       "         30: 7366,\n",
       "         50: 4466,\n",
       "         6: 6680,\n",
       "         36: 6438,\n",
       "         34: 6742,\n",
       "         58: 3503,\n",
       "         70: 2427,\n",
       "         62: 3135,\n",
       "         2: 1738,\n",
       "         52: 4179,\n",
       "         104: 725,\n",
       "         66: 2788,\n",
       "         128: 275,\n",
       "         68: 2434,\n",
       "         80: 1660,\n",
       "         126: 295,\n",
       "         56: 3741,\n",
       "         60: 3446,\n",
       "         7: 125,\n",
       "         118: 416,\n",
       "         64: 2887,\n",
       "         76: 1968,\n",
       "         74: 2130,\n",
       "         96: 920,\n",
       "         122: 321,\n",
       "         100: 843,\n",
       "         84: 1446,\n",
       "         82: 1588,\n",
       "         88: 1260,\n",
       "         78: 1954,\n",
       "         92: 1052,\n",
       "         114: 489,\n",
       "         90: 1259,\n",
       "         98: 806,\n",
       "         132: 317,\n",
       "         106: 610,\n",
       "         102: 768,\n",
       "         120: 405,\n",
       "         124: 362,\n",
       "         112: 498,\n",
       "         94: 1037,\n",
       "         116: 464,\n",
       "         23: 68,\n",
       "         5: 240,\n",
       "         31: 37,\n",
       "         130: 261,\n",
       "         184: 68,\n",
       "         138: 207,\n",
       "         162: 62,\n",
       "         212: 16,\n",
       "         154: 110,\n",
       "         144: 162,\n",
       "         160: 112,\n",
       "         140: 176,\n",
       "         41: 23,\n",
       "         110: 495,\n",
       "         136: 218,\n",
       "         134: 270,\n",
       "         158: 96,\n",
       "         142: 178,\n",
       "         108: 605,\n",
       "         9: 121,\n",
       "         156: 139,\n",
       "         146: 169,\n",
       "         168: 87,\n",
       "         148: 140,\n",
       "         170: 67,\n",
       "         152: 78,\n",
       "         150: 126,\n",
       "         166: 76,\n",
       "         182: 86,\n",
       "         186: 50,\n",
       "         216: 32,\n",
       "         202: 25,\n",
       "         17: 97,\n",
       "         19: 63,\n",
       "         21: 48,\n",
       "         188: 35,\n",
       "         172: 51,\n",
       "         176: 102,\n",
       "         180: 81,\n",
       "         13: 98,\n",
       "         11: 117,\n",
       "         77: 4,\n",
       "         61: 11,\n",
       "         81: 4,\n",
       "         67: 3,\n",
       "         33: 31,\n",
       "         15: 111,\n",
       "         37: 52,\n",
       "         164: 80,\n",
       "         25: 47,\n",
       "         59: 13,\n",
       "         178: 37,\n",
       "         29: 32,\n",
       "         53: 15,\n",
       "         49: 18,\n",
       "         51: 10,\n",
       "         200: 69,\n",
       "         214: 9,\n",
       "         246: 16,\n",
       "         190: 19,\n",
       "         242: 30,\n",
       "         256: 11,\n",
       "         174: 81,\n",
       "         258: 11,\n",
       "         232: 27,\n",
       "         294: 14,\n",
       "         226: 5,\n",
       "         192: 78,\n",
       "         194: 42,\n",
       "         196: 42,\n",
       "         27: 30,\n",
       "         3: 15,\n",
       "         35: 23,\n",
       "         206: 22,\n",
       "         119: 1,\n",
       "         220: 18,\n",
       "         250: 2,\n",
       "         272: 11,\n",
       "         280: 19,\n",
       "         384: 15,\n",
       "         230: 29,\n",
       "         218: 18,\n",
       "         396: 15,\n",
       "         404: 9,\n",
       "         348: 14,\n",
       "         394: 19,\n",
       "         306: 4,\n",
       "         198: 50,\n",
       "         222: 7,\n",
       "         378: 13,\n",
       "         336: 11,\n",
       "         376: 12,\n",
       "         362: 6,\n",
       "         210: 26,\n",
       "         75: 5,\n",
       "         39: 16,\n",
       "         302: 20,\n",
       "         101: 1,\n",
       "         228: 17,\n",
       "         238: 11,\n",
       "         236: 6,\n",
       "         298: 3,\n",
       "         208: 12,\n",
       "         99: 1,\n",
       "         204: 37,\n",
       "         276: 3,\n",
       "         370: 4,\n",
       "         324: 2,\n",
       "         386: 1,\n",
       "         350: 2,\n",
       "         330: 1,\n",
       "         300: 12,\n",
       "         260: 11,\n",
       "         340: 23,\n",
       "         234: 5,\n",
       "         240: 17,\n",
       "         262: 4,\n",
       "         248: 37,\n",
       "         268: 9,\n",
       "         320: 10,\n",
       "         278: 17,\n",
       "         328: 2,\n",
       "         426: 1,\n",
       "         466: 1,\n",
       "         392: 1,\n",
       "         346: 20,\n",
       "         460: 1,\n",
       "         488: 1,\n",
       "         520: 1,\n",
       "         382: 1,\n",
       "         508: 2,\n",
       "         372: 11,\n",
       "         504: 1,\n",
       "         270: 6,\n",
       "         296: 18,\n",
       "         286: 13,\n",
       "         432: 5,\n",
       "         440: 3,\n",
       "         244: 12,\n",
       "         282: 3,\n",
       "         344: 1,\n",
       "         422: 1,\n",
       "         434: 1,\n",
       "         364: 1,\n",
       "         326: 11,\n",
       "         292: 1,\n",
       "         224: 12,\n",
       "         91: 2,\n",
       "         57: 7,\n",
       "         43: 25,\n",
       "         69: 3,\n",
       "         254: 1,\n",
       "         252: 14,\n",
       "         312: 1,\n",
       "         274: 2,\n",
       "         318: 2,\n",
       "         334: 1,\n",
       "         522: 1,\n",
       "         584: 1,\n",
       "         616: 1,\n",
       "         572: 1,\n",
       "         640: 1,\n",
       "         474: 1,\n",
       "         610: 1,\n",
       "         358: 1,\n",
       "         446: 1,\n",
       "         438: 1,\n",
       "         400: 1,\n",
       "         618: 1,\n",
       "         582: 1,\n",
       "         644: 1,\n",
       "         650: 1,\n",
       "         696: 1,\n",
       "         79: 9,\n",
       "         47: 11,\n",
       "         139: 3,\n",
       "         45: 24,\n",
       "         310: 3,\n",
       "         127: 3,\n",
       "         159: 1,\n",
       "         65: 8,\n",
       "         63: 7,\n",
       "         308: 2,\n",
       "         266: 5,\n",
       "         55: 11,\n",
       "         73: 6,\n",
       "         103: 2,\n",
       "         115: 4,\n",
       "         109: 3,\n",
       "         117: 1,\n",
       "         89: 1,\n",
       "         87: 2,\n",
       "         264: 6,\n",
       "         85: 1,\n",
       "         83: 5,\n",
       "         131: 1,\n",
       "         71: 9,\n",
       "         107: 1,\n",
       "         105: 2,\n",
       "         356: 1,\n",
       "         366: 1,\n",
       "         360: 12,\n",
       "         374: 14,\n",
       "         462: 7,\n",
       "         558: 5,\n",
       "         288: 2,\n",
       "         554: 1})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(c_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11730"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESH = 100\n",
    "\n",
    "counter = 0\n",
    "for k, v in Counter(c_lengths).items():\n",
    "    if not k <= THRESH:\n",
    "        counter += v\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenghts = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/datahdd/vmanuel/entity_typing_all_datasets/data/ontonotes/g_train_tree.json', 'r') as inp:\n",
    "    lines = [json.loads(l) for l in inp.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [01:02<00:00, 3997.98it/s]\n",
      "  0%|          | 352/251039 [00:00<01:11, 3514.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2 | 5.97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [01:24<00:00, 2976.52it/s]\n",
      "  0%|          | 225/251039 [00:00<01:51, 2247.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4 | 9.52\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [01:41<00:00, 2468.99it/s]\n",
      "  0%|          | 257/251039 [00:00<01:37, 2569.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6 | 12.70\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [02:00<00:00, 2089.26it/s]\n",
      "  0%|          | 227/251039 [00:00<01:50, 2261.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8 | 15.52\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [02:13<00:00, 1883.79it/s]\n",
      "  0%|          | 221/251039 [00:00<01:53, 2203.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10 | 18.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [02:23<00:00, 1745.55it/s]\n",
      "  0%|          | 213/251039 [00:00<01:57, 2127.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12 | 20.18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [02:33<00:00, 1637.46it/s]\n",
      "  0%|          | 202/251039 [00:00<02:04, 2018.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14 | 22.07\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [02:44<00:00, 1528.49it/s]\n",
      "  0%|          | 172/251039 [00:00<02:26, 1715.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16 | 23.70\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [02:52<00:00, 1454.74it/s]\n",
      "  0%|          | 193/251039 [00:00<02:10, 1928.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18 | 25.11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251039/251039 [02:57<00:00, 1410.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20 | 26.31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for le in lenghts:\n",
    "    token_number = []\n",
    "    for l in tqdm(lines):\n",
    "        left = l['left_context_token'][-le:]\n",
    "        right = l['right_context_token'][:le]\n",
    "        sentence = ' '.join(left) + ' ' + ' '.join(right)\n",
    "        t = tokenizer(sentence)\n",
    "        token_number.append(len(t['input_ids']))\n",
    "    print(' {:2d} | {:.2f}\\n'.format(le, np.mean(token_number)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes weights check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'datasets_stats/ontonotes_train_weights.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'rb') as inp:\n",
    "    ws = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/other': 0.6326945215683619,\n",
       " '/other/body_part': 0.9818235413620992,\n",
       " '/person/title': 0.8487486008150128,\n",
       " '/person': 0.643358203307056,\n",
       " '/person/athlete': 0.9937698923274869,\n",
       " '/other/art': 0.9297519508920925,\n",
       " '/other/art/music': 0.984651787172511,\n",
       " '/other/event': 0.953572950816407,\n",
       " '/other/event/holiday': 0.9900931727739515,\n",
       " '/other/religion': 0.9894120037125705,\n",
       " '/location/country': 0.9093806141675198,\n",
       " '/location': 0.7586709634757947,\n",
       " '/other/currency': 0.9834089523938512,\n",
       " '/other/food': 0.9850142806496202,\n",
       " '/other/health/malady': 0.9695624982572429,\n",
       " '/other/health': 0.9537123713845259,\n",
       " '/person/religious_leader': 0.9856556152629671,\n",
       " '/other/product': 0.9620855723612666,\n",
       " '/other/internet': 0.9816562366803564,\n",
       " '/person/artist/author': 0.8844880675910914,\n",
       " '/person/artist': 0.8586036432586172,\n",
       " '/other/health/treatment': 0.9841419062376762,\n",
       " '/location/city': 0.9426304279414752,\n",
       " '/location/transit/road': 0.9991833938153036,\n",
       " '/location/transit': 0.9990599070263982,\n",
       " '/organization/company/news': 0.9669573253558212,\n",
       " '/other/art/writing': 0.9592174921028207,\n",
       " '/organization': 0.8244495875142906,\n",
       " '/organization/company': 0.9136389166623513,\n",
       " '/other/living_thing/animal': 0.9913160903285944,\n",
       " '/other/living_thing': 0.9728647739992591,\n",
       " '/other/supernatural': 0.9588350814016946,\n",
       " '/organization/music': 0.9930488888180721,\n",
       " '/other/event/violent_conflict': 0.9835005716243292,\n",
       " '/location/structure': 0.9643282517855791,\n",
       " '/organization/military': 0.9862172809802461,\n",
       " '/location/structure/government': 0.9736216285119045,\n",
       " '/person/artist/director': 0.9936742896522054,\n",
       " '/person/artist/music': 0.9894398878261943,\n",
       " '/other/product/software': 0.9908181597281698,\n",
       " '/location/celestial': 0.9968530786053164,\n",
       " '/organization/education': 0.9874282482004788,\n",
       " '/other/product/weapon': 0.9975939993387481,\n",
       " '/person/political_figure': 0.9145351917431156,\n",
       " '/other/art/broadcast': 0.9938137102203244,\n",
       " '/person/military': 0.9582853660188257,\n",
       " '/location/park': 0.9996454734124977,\n",
       " '/other/sports_and_leisure': 0.997773254354901,\n",
       " '/other/art/film': 0.9914116930038759,\n",
       " '/location/geography/body_of_water': 0.9960763068686539,\n",
       " '/location/geography': 0.9946940515218751,\n",
       " '/other/language': 0.9905871199295727,\n",
       " '/other/scientific': 0.9824927600890698,\n",
       " '/other/event/natural_disaster': 0.9953035185767949,\n",
       " '/person/artist/actor': 0.9346555714450743,\n",
       " '/organization/government': 0.9706977800262111,\n",
       " '/other/heritage': 0.9901608913356093,\n",
       " '/other/product/car': 0.9966658566995567,\n",
       " '/organization/company/broadcast': 0.9922880508606232,\n",
       " '/organization/political_party': 0.991814020929019,\n",
       " '/location/structure/airport': 0.999438334282721,\n",
       " '/other/art/stage': 0.9987013969940925,\n",
       " '/location/structure/theater': 0.9992232282633375,\n",
       " '/other/event/election': 0.9957058465019379,\n",
       " '/location/geography/island': 0.9992431454873546,\n",
       " '/organization/transit': 0.9986376618772382,\n",
       " '/location/geography/mountain': 0.9994024832794904,\n",
       " '/organization/sports_team': 0.9964666844593868,\n",
       " '/person/legal': 0.99374997510347,\n",
       " '/other/event/protest': 0.9959687538589621,\n",
       " '/other/legal': 0.9982990690689495,\n",
       " '/organization/sports_league': 0.9987332645525198,\n",
       " '/location/structure/sports_facility': 0.9995817382956433,\n",
       " '/location/geograpy/island': 0.9996335230780875,\n",
       " '/location/geograpy': 0.9996335230780875,\n",
       " '/location/structure/hospital': 0.9996614071917113,\n",
       " '/person/doctor': 0.9993945163898836,\n",
       " '/other/event/accident': 0.9998645628766845,\n",
       " '/location/structure/restaurant': 0.9995498707372161,\n",
       " '/other/award': 0.9996096224092671,\n",
       " '/person/coach': 0.9996853078605317,\n",
       " '/other/language/programming_language': 0.9996733575261214,\n",
       " '/other/product/computer': 0.9996175892988739,\n",
       " '/other/event/sports_event': 0.9996972581949418,\n",
       " '/organization/stock_exchange': 0.9983468704065902,\n",
       " '/location/structure/hotel': 0.9998048112046335,\n",
       " '/location/transit/bridge': 0.9998964304351117,\n",
       " '/location/transit/railway': 0.999980082775983,\n",
       " '/other/product/mobile_phone': 0.9999203311039321}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choi classes check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/datahdd/vmanuel/entity_typing_all_datasets/data/lopez_data/crowd/train_m.json'\n",
    "dev_path = '/datahdd/vmanuel/entity_typing_all_datasets/data/lopez_data/crowd/dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(train_path, 'r') as inp:\n",
    "    lines = [json.loads(l) for l in inp.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [label for l in lines for label in l['y_str']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el_train_labels = set(train_labels)\n",
    "# headword_train_labels = set(train_labels)\n",
    "m_train_labels = set(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dev_path, 'r') as inp:\n",
    "    lines = [json.loads(l) for l in inp.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_labels = [label for l in lines for label in l['y_str']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_labels = set(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4056"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(el_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8170"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headword_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1639"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1269"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(el_train_labels.intersection(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1465"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headword_train_labels.intersection(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_labels = headword_train_labels.union(el_train_labels.union(m_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8763"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1636"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_train_labels.intersection(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = [i for i in range(1, 14) for j in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0157\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "won = 0\n",
    "iterations=10000\n",
    "for _ in range(iterations):\n",
    "    shuffle(cards)\n",
    "    lost = False\n",
    "    i = 0\n",
    "    while not lost and i < len(cards):\n",
    "        c = cards[i]\n",
    "        if (i + 1) % 13 + 1 == c:\n",
    "            lost = True\n",
    "        i += 1\n",
    "    if not lost:\n",
    "        won += 1\n",
    "print(won/iterations)\n",
    "print(won)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = '/datahdd/vmanuel/entity_typing_all_datasets/data/BBN/BBN/train_partitioned.json'\n",
    "test_dataset = '/datahdd/vmanuel/entity_typing_all_datasets/data/BBN/BBN/test_lines.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_token = 10\n",
    "context_token = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(train_dataset, 'r') as inp:\n",
    "    train_lines = [json.loads(l) for l in inp.readlines()]\n",
    "with open(test_dataset, 'r') as inp:\n",
    "    test_lines = [json.loads(l) for l in inp.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "aux_variable = 'dataloaders/Bert_Baseline_bbn_train_auxiliary_variables.pkl'\n",
    "\n",
    "with open(aux_variable, 'rb') as inp:\n",
    "    id2label, label2id, vocab_len = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_model.models.BERT_models import ConcatenatedContextBERTTyper\n",
    "\n",
    "pre_trained_model = 'checkpoints/B_BBN/model_1.ckpt'\n",
    "\n",
    "model = ConcatenatedContextBERTTyper.load_from_checkpoint(pre_trained_model, \n",
    "                                                          classes = vocab_len, \n",
    "                                                          id2label = id2label, \n",
    "                                                          label2id = label2id, \n",
    "                                                          weights = None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mentions_and_contexts(leng, lines, batch_size = 2):\n",
    "    train_mentions = [t['mention_span'] for t in lines[:leng]] \n",
    "\n",
    "    train_left_side = [t['left_context_token'] for t in lines[:leng]]\n",
    "    train_right_side = [t['right_context_token'] for t in lines[:leng]]\n",
    "    \n",
    "    labels = [t['y_str'] for t in lines[:leng]]\n",
    "\n",
    "    extracted_left_side = [' '.join(l[- int(np.floor(context_token/2)):]) for l in train_left_side]\n",
    "    extracted_right_side = [' '.join(r[: int(np.floor(context_token/2))]) for r in train_right_side]\n",
    "    \n",
    "    mentions = [torch.tensor(t) for t in tokenizer(train_mentions,\n",
    "                                                    padding='max_length',\n",
    "                                                    max_length = mention_token,\n",
    "                                                    truncation=True,\n",
    "                                                    return_tensors=\"pt\")['input_ids'].tolist()]\n",
    "    \n",
    "    contexts = [l + ' ' + r for l, r in zip(extracted_left_side, extracted_right_side)]\n",
    "    contexts = [torch.tensor(t) for t in tokenizer(contexts,\n",
    "                                                    padding='max_length',\n",
    "                                                    max_length = context_token,\n",
    "                                                    truncation=True,\n",
    "                                                    return_tensors=\"pt\")['input_ids'].tolist()]\n",
    "    \n",
    "    batched = [(torch.stack([mentions[j + i] for i in range(batch_size)]).cuda(), \n",
    "                torch.stack([contexts[j + i] for i in range(batch_size)]).cuda(),\n",
    "               [labels[j + i] for i in range(batch_size)])\n",
    "                   for j in range(0, leng, int(leng/(leng/batch_size)))]\n",
    "    \n",
    "    return batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batched= get_mentions_and_contexts(10, train_lines)\n",
    "test_batched = get_mentions_and_contexts(10, test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[ 101, 9781,  102,    0,    0,    0,    0,    0,    0,    0],\n",
       "          [ 101, 1996,  102,    0,    0,    0,    0,    0,    0,    0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101,  2095,  1005,  1055, 14734,  1011, 25537,  3947,  1024,  1996,\n",
       "            2231, 10035,  6434,  2012,  1021,   102],\n",
       "          [  101,  7564,  2044,  2197,  2095,  1005,  1055, 14734,  1011, 25537,\n",
       "            3947,  1024,  2231, 10035,  9781,   102]], device='cuda:0'),\n",
       "  [['/PLANT', '/PRODUCT', '/SUBSTANCE', '/SUBSTANCE/FOOD'],\n",
       "   ['/ORGANIZATION/CORPORATION',\n",
       "    '/WORK_OF_ART',\n",
       "    '/ORGANIZATION',\n",
       "    '/WORK_OF_ART/BOOK']]),\n",
       " (tensor([[  101, 18370,  2015,   102,     0,     0,     0,     0,     0,     0],\n",
       "          [  101, 25176,  4783,  2319,   102,     0,     0,     0,     0,     0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101, 25176,  4783,  2319,  2537,  2484,  1003,  1012,   102,     0,\n",
       "               0,     0,     0,     0,     0,     0],\n",
       "          [  101,  2537, 18370,  2015,  2484,  1003,  1012,   102,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0]], device='cuda:0'),\n",
       "  [['/DISEASE'], ['/PLANT', '/PRODUCT', '/SUBSTANCE', '/SUBSTANCE/FOOD']]),\n",
       " (tensor([[ 101, 7975, 5438,  102,    0,    0,    0,    0,    0,    0],\n",
       "          [ 101, 2765,  102,    0,    0,    0,    0,    0,    0,    0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101,  1999,  3688,  2004,  7578,  2004, 11957, 16031,  1998,  1010,\n",
       "           22088, 11368,  2322,  1003,  2000,   102],\n",
       "          [  101,  2004,  1037,  1010,  7597,  3825,  2000,  6617,  2005,  1996,\n",
       "           21955,   102,     0,     0,     0,     0]], device='cuda:0'),\n",
       "  [['/PLANT', '/ANIMAL'], ['/GAME']]),\n",
       " (tensor([[  101,  2004,   102,     0,     0,     0,     0,     0,     0,     0],\n",
       "          [  101, 22171,   102,     0,     0,     0,     0,     0,     0,     0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[ 101, 1037, 2765, 1010, 7597, 3825, 2000, 6617, 2005,  102,    0,    0,\n",
       "              0,    0,    0,    0],\n",
       "          [ 101, 5987, 7325, 2833, 7597, 2000, 5376, 1019, 1012, 1019, 1003,  102,\n",
       "              0,    0,    0,    0]], device='cuda:0'),\n",
       "  [['/SUBSTANCE/CHEMICAL', '/SUBSTANCE'],\n",
       "   ['/ORGANIZATION', '/ORGANIZATION/EDUCATIONAL']]),\n",
       " (tensor([[  101, 12486,   102,     0,     0,     0,     0,     0,     0,     0],\n",
       "          [  101, 28822,   102,     0,     0,     0,     0,     0,     0,     0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101,  7597,  1010, 16349,  2379,  2636,  2144,  1996, 14734,   102,\n",
       "               0,     0,     0,     0,     0,     0],\n",
       "          [  101,  4530,  1999, 17300,  2023,  3467,  2065,  8086,  2545,  7818,\n",
       "            1012,   102,     0,     0,     0,     0]], device='cuda:0'),\n",
       "  [['/PRODUCT', '/SUBSTANCE', '/SUBSTANCE/FOOD'], ['/PLANT', '/ANIMAL']])]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[  101,  5578, 19354,  7520,   102,     0,     0,     0,     0,     0],\n",
       "          [  101, 19354,  7520,   102,     0,     0,     0,     0,     0,     0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101,  1010,  6079,  2086,  2214,  1010,  2097,  3693,  1996,   102,\n",
       "               0,     0,     0,     0,     0,     0],\n",
       "          [  101,  2720,  1012,  2003,  3472,  1997,  2842, 14356,  1050,  1012,\n",
       "            1058,  1012,  1010,  1996,  3803,   102]], device='cuda:0'),\n",
       "  [['/PERSON'], ['/PERSON']]),\n",
       " (tensor([[  101, 21307,  2278,   102,     0,     0,     0,     0,     0,     0],\n",
       "          [  101,  2769,  4636,  3189,   102,     0,     0,     0,     0,     0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101, 10750,  1997,  1996,  4278, 23726,  3468,  5029, 12808,  2011,\n",
       "            1005,  1055,  2769,  4636,  3189,   102],\n",
       "          [  101,  1996,  4278, 23726,  3468,  5029, 12808,  2011, 21307,  2278,\n",
       "            1005,  1055, 10987,  1037, 12884,   102]], device='cuda:0'),\n",
       "  [['/ORGANIZATION/CORPORATION', '/ORGANIZATION'], ['/ORGANIZATION']]),\n",
       " (tensor([[  101,  2123,  8649, 20169,  1005,  1055,   102,     0,     0,     0],\n",
       "          [  101, 15507, 16007, 12871, 11265, 12349,   102,     0,     0,     0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101,  1996,  6493,  2144,  2220,  2257,  1010,  2429,  2000,  1012,\n",
       "             102,     0,     0,     0,     0,     0],\n",
       "          [  101,  6600,  1010,  2056,  1010,  3559,  1997,  2769,  4636,  3189,\n",
       "            1010, 16189,   102,     0,     0,     0]], device='cuda:0'),\n",
       "  [['/ORGANIZATION/CORPORATION', '/ORGANIZATION'], ['/PERSON']]),\n",
       " (tensor([[ 101, 2769, 4636, 3189,  102,    0,    0,    0,    0,    0],\n",
       "          [ 101, 9837,  102,    0,    0,    0,    0,    0,    0,    0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101,  1010,  2056, 15507, 16007, 12871, 11265, 12349,  1010,  3559,\n",
       "            1997,  1010, 16189,  1036,  1036,   102],\n",
       "          [  101,  1996, 10750,  2006,  2416,  1011,  3204,  8236,  2853,  2012,\n",
       "            6928,  1005,  1055, 10470,  1010,   102]], device='cuda:0'),\n",
       "  [['/ORGANIZATION'], ['/ORGANIZATION/GOVERNMENT', '/ORGANIZATION']]),\n",
       " (tensor([[  101,  1046,  1012,  1052,  1012,  7782, 14194,   102,     0,     0],\n",
       "          [  101,  1059,  1012,  1054,  1012,  4519,  1004,  2522,  1012,   102]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101,  1010,  3580,  3472,  1997,  1059,  1012,  1054,  1012,  4519,\n",
       "            1004,  2522,  1012,   102,     0,     0],\n",
       "          [  101,  1046,  1012,  1052,  1012,  7782, 14194,  1010,  3580,  3472,\n",
       "            1997,  1010,  2029,  4324,  1037,   102]], device='cuda:0'),\n",
       "  [['/PERSON'], ['/ORGANIZATION/CORPORATION', '/ORGANIZATION']])]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConcatenatedContextBERTTyper(\n",
       "  (sig): Sigmoid()\n",
       "  (classification_loss): BCEWithLogitsLoss()\n",
       "  (micro_precision): Precision()\n",
       "  (micro_recall): Recall()\n",
       "  (micro_f1): F1()\n",
       "  (macro_precision): Precision()\n",
       "  (macro_recall): Recall()\n",
       "  (macro_f1): F1()\n",
       "  (my_metrics): MyMetrics()\n",
       "  (input_encoder): BertEncoder(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (context_pooler): AvgPool2d(kernel_size=(16, 1), stride=(16, 1), padding=0)\n",
       "  (context_transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (context_to_hidden): Linear(in_features=768, out_features=200, bias=True)\n",
       "  (mention_pooler): AvgPool2d(kernel_size=(9, 1), stride=(9, 1), padding=0)\n",
       "  (mention_to_hidden): Linear(in_features=768, out_features=200, bias=True)\n",
       "  (hidden_to_hidden): Linear(in_features=400, out_features=400, bias=True)\n",
       "  (hidden_to_output): Linear(in_features=400, out_features=47, bias=True)\n",
       "  (droppy): Dropout(p=0.2, inplace=False)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_pred(pred):\n",
    "    mask = pred > .5\n",
    "    batch_preds = []\n",
    "    for i, m in enumerate(mask):\n",
    "        ex_preds = []   \n",
    "        pred_ids =  m.nonzero()\n",
    "\n",
    "        if len(pred_ids) == 0:\n",
    "            pred_ids = [torch.argmax(pred[i])]\n",
    "        for p in pred_ids:\n",
    "            ex_preds.append(id2label[p.item()])\n",
    "        batch_preds.append(ex_preds)\n",
    "    return batch_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_batched)\n",
    "test_iter = iter(test_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions, contexts, labels = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sig(model(mentions, contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['/SUBSTANCE/FOOD', '/SUBSTANCE'], ['/PERSON']],\n",
       " [['/PLANT', '/PRODUCT', '/SUBSTANCE', '/SUBSTANCE/FOOD'],\n",
       "  ['/ORGANIZATION/CORPORATION',\n",
       "   '/WORK_OF_ART',\n",
       "   '/ORGANIZATION',\n",
       "   '/WORK_OF_ART/BOOK']])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(test_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[  101,  5578, 19354,  7520,   102,     0,     0,     0,     0,     0],\n",
       "          [  101, 19354,  7520,   102,     0,     0,     0,     0,     0,     0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101,  1010,  6079,  2086,  2214,  1010,  2097,  3693,  1996,   102,\n",
       "               0,     0,     0,     0,     0,     0],\n",
       "          [  101,  2720,  1012,  2003,  3472,  1997,  2842, 14356,  1050,  1012,\n",
       "            1058,  1012,  1010,  1996,  3803,   102]], device='cuda:0'),\n",
       "  [['/PERSON'], ['/PERSON']]),\n",
       " (tensor([[  101, 21307,  2278,   102,     0,     0,     0,     0,     0,     0],\n",
       "          [  101,  2769,  4636,  3189,   102,     0,     0,     0,     0,     0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101, 10750,  1997,  1996,  4278, 23726,  3468,  5029, 12808,  2011,\n",
       "            1005,  1055,  2769,  4636,  3189,   102],\n",
       "          [  101,  1996,  4278, 23726,  3468,  5029, 12808,  2011, 21307,  2278,\n",
       "            1005,  1055, 10987,  1037, 12884,   102]], device='cuda:0'),\n",
       "  [['/ORGANIZATION/CORPORATION', '/ORGANIZATION'], ['/ORGANIZATION']]),\n",
       " (tensor([[  101,  2123,  8649, 20169,  1005,  1055,   102,     0,     0,     0],\n",
       "          [  101, 15507, 16007, 12871, 11265, 12349,   102,     0,     0,     0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101,  1996,  6493,  2144,  2220,  2257,  1010,  2429,  2000,  1012,\n",
       "             102,     0,     0,     0,     0,     0],\n",
       "          [  101,  6600,  1010,  2056,  1010,  3559,  1997,  2769,  4636,  3189,\n",
       "            1010, 16189,   102,     0,     0,     0]], device='cuda:0'),\n",
       "  [['/ORGANIZATION/CORPORATION', '/ORGANIZATION'], ['/PERSON']]),\n",
       " (tensor([[ 101, 2769, 4636, 3189,  102,    0,    0,    0,    0,    0],\n",
       "          [ 101, 9837,  102,    0,    0,    0,    0,    0,    0,    0]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101,  1010,  2056, 15507, 16007, 12871, 11265, 12349,  1010,  3559,\n",
       "            1997,  1010, 16189,  1036,  1036,   102],\n",
       "          [  101,  1996, 10750,  2006,  2416,  1011,  3204,  8236,  2853,  2012,\n",
       "            6928,  1005,  1055, 10470,  1010,   102]], device='cuda:0'),\n",
       "  [['/ORGANIZATION'], ['/ORGANIZATION/GOVERNMENT', '/ORGANIZATION']]),\n",
       " (tensor([[  101,  1046,  1012,  1052,  1012,  7782, 14194,   102,     0,     0],\n",
       "          [  101,  1059,  1012,  1054,  1012,  4519,  1004,  2522,  1012,   102]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[  101,  1010,  3580,  3472,  1997,  1059,  1012,  1054,  1012,  4519,\n",
       "            1004,  2522,  1012,   102,     0,     0],\n",
       "          [  101,  1046,  1012,  1052,  1012,  7782, 14194,  1010,  3580,  3472,\n",
       "            1997,  1010,  2029,  4324,  1037,   102]], device='cuda:0'),\n",
       "  [['/PERSON'], ['/ORGANIZATION/CORPORATION', '/ORGANIZATION']])]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions, contexts, labels = next(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sig(model(mentions, contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['/PERSON'], ['/ORGANIZATION', '/ORGANIZATION/CORPORATION']],\n",
       " [['/PERSON'], ['/ORGANIZATION/CORPORATION', '/ORGANIZATION']])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label_pred(pred), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_path = 'dataloaders/bbn_test.pkl'\n",
    "with open(dataloader_path, \"rb\") as filino:\n",
    "    dataloader = pickle.load(filino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2][0].view([1, 39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/FACILITY']]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label_pred(a[2][0].view(1, 39))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/PERSON']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BatchNorm1d\n",
    "\n",
    "batch_n = BatchNorm1d(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([[float(i) for i in range(10)] for j in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"batch_norm\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b0e4f616e31e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/typing_network/another_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/typing_network/another_env/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/typing_network/another_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   2015\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m     )\n\u001b[1;32m   2018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"batch_norm\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "batch_n(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
